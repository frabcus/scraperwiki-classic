<div class="section">
  <p>The Ruby environment in Scraperwiki comes with the ScraperWiki module loaded</p>

  <p>The source code implementation of these functions can be found 
  <a href="https://bitbucket.org/ScraperWiki/scraperwiki/src/efd21ea1c875/scraperlibs/scraperwiki.rb">here</a>.</p>
</div>

<h3><span id="sql"></span>The SQLite datastore</h3>
<p>ScraperWiki provides a fully-fledged <a href="http://www.sqlite.org/lang.html">SQLite</a> database for each scraper which you can save to.  
You can read the data back that has been committed by other scrapers, or extract it through 
the API</p>

<dl>
<dt>ScraperWiki.<strong>save_sqlite</strong>(unique_keys, data[, table_name="swdata", verbose=2])</dt>
    <dd>Saves a data record represented by the hash data into the table given by table_name.  </dd>
    <dd>unique_keys is an array that is a subset of data.keys which determins 
        when a record is to be over-written.
    </dd>

<dt>ScraperWiki.<strong>attach</strong>(name[, asname])</dt>
    <dd>Attaches to the datastore of another scraper of name name.</dd>
    <dd>asname is an optional alias for the attached datastore.
    </dd>

<dt>ScraperWiki.<strong>select</strong>(val1[, val2])</dt>
    <dd>Executes a select command on the datastore, eg select("* from swdata limit 10")</dd>
    <dd>Returns an array of hashes for the records that have been selected</dd>
        val2 is an optional array of parameters when the select command string contains '?'s
    </dd>


<dt>ScraperWiki.<strong>sqliteexecute</strong>(val1[, val2])</dt>
    <dd>Executes any arbitrary sqlite command (except attach), eg create, delete, insert or drop</dd>
    <dd>val2 is an optional indexed array of parameters if the command in val1 contains question marks</dd>
    <dd>(eg "insert into swdata values (?,?,?)").
    </dd>

<dt>ScraperWiki.<strong>sqlitecommit</strong>()</dt>
    <dd>Commits to the file after a series of execute commands.  (save_sqlite() auto-commits after every action).
    </dd>

<dt>ScraperWiki.<strong>show_tables</strong>([dbname])</dt>
    <dd>Returns an array of tables and their schemas in either the current or an attached database.</dd>

<dt>ScraperWiki.<strong>table_info</strong>(name)</dt>
    <dd>Returns an array of attributes for each element of the table</dd>

<dt>ScraperWiki.<strong>save_var</strong>(key, value)</dt>
    <dd>Saves an arbitrary single-value into a sqlite table called "swvariables". 
        Used to make scrapers able to continue after an interruption.
    </dd>

<dt>ScraperWiki.<strong>get_var</strong>(key[, default])</dt>
    <dd>Retrieves a single value that was saved by save_var.
    </dd>

</dl>



<h3>Geocoding functions</h3>

<dl>

<dt>ScraperWiki.<strong>gb_postcode_to_latlng</strong>(postcode)</dt>
    <dd>Returns an array [lat, lng] in WGS84 coordinates representing the central point of a UK postcode area.
    </dd>

</dl>


<h3>Misc data format functions</h3>
<dl>

<dt>ScraperWiki.<strong>scrape</strong>(url[, params])</dt>
    <dd>Returns the downloaded string from the given url</dd>
    <dd>params are send as a POST if set.
    </dd>

<dt>ScraperWiki.<strong>httpresponseheader</strong>(headerkey, headervalue)</dt>
    <dd>Set the content-type header to something other than HTML when using a Scraperwiki "view"</dd>
    <dd>(eg "Content-Type", "image/PNG")
    </dd>

</dl>
