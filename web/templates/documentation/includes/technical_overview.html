{% load doc_links %}

<h2>All the techy bits of ScraperWiki in one list</h2>

<ul>
    <li>Edit code with a browser-based code editor, it's called <a href="http://codemirror.net/">CodeMirror</a>.</li>
    <li>Normal Python, Ruby and PHP scripts run in a sandbox on ScraperWiki's servers.</li>
    <li>Nokogiri, lxml, Mechanize &mdash; all the {% doc_link_full 'LANG_libraries' language %} you're used to.</li>
    <li>{% doc_link_full 'LANG_help_documentation' language %} makes scraping and storing data simple.</li>
    <li>Data is stored direct in a SQLite datastore, schemaless unless you want control ({% doc_link_full 'LANG_datastore_guide' language %}).</li>
    <li>Access to data in JSON or CSV using SQL in URLs via the <a href="{% url docsexternal %}">ScraperWiki external API</a>.</li>
    <li>Views for exporting the data in any format, or writing simple web apps. They're CGI scripts.</li>
    <li>Scheduled to re-run daily so your data is always up-to-date. See scraper overview page.</li>
    <li>Email alerts if your scrapers fail, or someone edits them.</li>
    <li>Autocommits to built in source control, based on Mercurial. See the history tab.</li>
</ul>


