<div class="documentationpage">

<div class="section">
<p>The PHP environment in Scraperwiki comes loaded with special functions in the name-space "scraperwiki::"</p>

<p>The source code implementation of these functions can be found 
<a href="https://bitbucket.org/ScraperWiki/scraperwiki/src/efd21ea1c875/scraperlibs/scraperwiki.php">here</a>.</p>
</div>

<h3><span id="sql"></span>The SQLite datastore</h3>
<p>ScraperWiki provides a fully-fledged <a href="http://www.sqlite.org/lang.html">SQLite</a> database for each scraper which you can save to.  
You can read the data back that has been committed by other scrapers, or extract it through 
the API</p>

<dl>
<dt>scraperwiki::<strong>save_sqlite</strong>($unique_keys, $data[, $table_name="swdata", $verbose=2])</dt>
    <dd>Saves a data record represented by the key array $data into the table given by $table_name.  <dd>
    <dd>$unique_keys must be an array that is a subset of array_keys($data) which determins 
        when a record is over-written.
    </dd>

<dt>scraperwiki::<strong>attach</strong>($name[, $asname])</dt>
    <dd>Attaches to the datastore of another scraper of name $name.</dd>
    <dd>$asname is an optional alias for the attached datastore.
    </dd>

<dt>scraperwiki::<strong>select</strong>($val1[, $val2])</dt>
    <dd>Executes a select command on the datastore, eg select("* from swdata limit 10")</dd>
    <dd>Returns an array of key arrays for the records that have been selected</dd>
    <dd>$val2 is an optional list of parameters if the select command contains '?'s
    </dd>


<dt>scraperwiki::<strong>sqliteexecute</strong>($val1[, $val2])</dt>
    <dd>Executes any arbitrary sqlite command (except attach), eg create, delete, insert or drop</dd>
    <dd>$val2 is an optional indexed array of parameters if the command in $val1 contains question marks</dd>
    <dd>(eg "insert into swdata values (?,?,?)").
    </dd>

<dt>scraperwiki::<strong>sqlitecommit</strong>()</dt>
    <dd>Commits to the file after a series of execute commands.  (save_sqlite() auto-commits after every action).
    </dd>

<dt>scraperwiki::<strong>show_tables</strong>([$dbname])</dt>
    <dd>Returns an array of tables and their schemas in either the current or an attached database.</dd>

<dt>scraperwiki::<strong>table_info</strong>($name)</dt>
    <dd>Returns an array of attributes for each element of the table</dd>

<dt>scraperwiki::<strong>save_var</strong>($key, $value)</dt>
    <dd>Saves an arbitrary single-value into a sqlite table called "swvariables". 
        Used to make scrapers able to continue after an interruption.
    </dd>

<dt>scraperwiki::<strong>get_var</strong>($key[, $default])</dt>
    <dd>Retrieves a single value that was saved by save_var.
    </dd>

</dl>




<h3>Geocoding functions</h3>

<dl>
<dt>scraperwiki::<strong>gb_postcode_to_latlng</strong>($postcode)</dt>
    <dd>Returns an array($lat, $lng) in WGS84 coordinates representing the central point of a UK postcode area.
    </dd>

</dl>


<h3>Misc data format functions</h3>
<dl>

<dt>scraperwiki::<strong>scrape</strong>($url)</dt>
    <dd>Returns the downloaded string 
    </dd>

<dt>scraperwiki::<strong>httpresponseheader</strong>($headerkey, $headervalue)</dt>
    <dd>Set the content-type header to something other than HTML when using a Scraperwiki "view" </dd>
    <dd>(eg "Content-Type", "image/png")
    </dd>

</dl>

</div>

