<div class="documentationpage">
<h3>Scraperwiki Python documentation</h3>

<p>In your scrapers, you can use ScraperWiki's in-built functions for retrieving, geocoding and saving data. 
Just add <code>import scraperwiki</code> at the top of your scraper.</p>


<h3><span id="sql"></span>The SQLite datastore</h3>
<p>ScraperWiki provides a fully-fledged SQLite database for each scraper which you can save to.  
You can read the data back that has been committed by other scrapers, or extract it through 
the API</p>

<dl>
<dt>scraperwiki.<strong>sqlite.save</strong>(unique_keys, data[, table_name="swdata", verbose=2])</dt>
    <dd>Saves a data record into the datastore into the table given by table_name.  <br/>
        data is a dict object, unique_keys is a subset of data.keys() which determins 
        when a record is over-written.<br/>
        For large numbers of records data can be a list of dicts.
    </dd>

<dt>scraperwiki.<strong>sqlite.attach</strong>(name[, asname])</dt>
    <dd>Attaches to the datastore of another scraper with the given name.<br/>
        asname is an optional alias for the attached datastore.
    </dd>

<dt>scraperwiki.<strong>sqlite.select</strong>(val1[, val2], verbose=1)</dt>
    <dd>Executes a select command on the datastore, eg select("* from swdata limit 10")<br/>
        Returns a list of dicts that have been selected<br/>
        val2 is an optional list of parameters if the select command contains ?s
    </dd>

<dt>scraperwiki.<strong>sqlite.execute</strong>(val1[, val2, verbose=1])</dt>
    <dd>Executes any arbitrary sqlite command (except attach), eg create, delete, insert or drop<br/>
        val2 is an optional list of parameters if the select command contains question marks
    </dd>

<dt>scraperwiki.<strong>sqlite.commit</strong>()</dt>
    <dd>Commits to the file after a series of execute commands.  (sqlite.save auto-commits).
    </dd>

<dt>scraperwiki.<strong>sqlite.save_var</strong>(key, value)</dt>
    <dd>Saves an arbitrary single-value into a table called "swvariables". 
        Used to make scrapers able to continue after an interruption.
    </dd>

<dt>scraperwiki.<strong>sqlite.get_var</strong>(key[, default])</dt>
    <dd>Retrieves a single value that was saved by save_var.
    </dd>

</dl>




        <div class="section">
	    <h2><span id="geocoding"></span>Geocoding data</h2>
	    <p>ScraperWiki provides three useful geocoding functions: extract the postcode from an address;
	    convert postcode to lat/lng; and convert easting/northing to lat/lng.</p> 
	    <h4>Method</h4>
	    <table class="api_detail example_table">
	    <tr><th width="30%">Method</th><th width="20%">Returned value</th><th>Description</th></tr>
		<tr><td><code>scraperwiki.geo.extract_gb_postcode
		      <br/>&nbsp;(string)</code></td><td>String</td>
		    <td><p>Attempts to extract a UK postcode from a given string.</p>
            <dl>
              <dt><code>string</code></dt>
              <dd>String. The string (e.g. an address) that will be searched for a postcode. Returns 
                 <code>False</code> if no postcode can be found. </dd>
            </dl>
            </td>
		    </tr>
		<tr><td><code>scraperwiki.geo.gb_postcode_to_latlng
			      <br/>&nbsp;(postcode)</code></td><td>List</td>
		    <td>
		    <p>Find the lat/lng for a given postcode.</p>
	        <dl>
	          <dt><code>postcode</code></dt>
	          <dd>
	            String. The postcode to geocode. 
	            You can supply the returned value as the <code>latlng</code> field in 
	            <a href="#saving">scraperwiki.datastore.save</a>.
	          </dd>
	        </dl>
		    </td>
		    </tr>
		<tr><td><code>scraperwiki.geo.os_easting_northing_to_latlng
			      <br/>&nbsp;(easting, northing)</code></td><td>List</td>
		    <td>
		    <p>
              Convert <a href="http://en.wikipedia.org/wiki/British_national_grid_reference_system">OSGB</a>
              easting/northing to lat/lng. 
            </p>
            <dl>
              <dt><code>easting</code></dt>
              <dd>Integer. The easting of the point to be converted.</dd>
              <dt><code>northing</code></dt>
              <dd>Integer. The northing of the point to be converted.</dd>
            </dl>
		    </td>
		    </tr>	
	    </table>
		<h4>Example</h4>
		<div class="example"><code>
		postcode = scraperwiki.geo.extract_gb_postcode("10 Downing Street, London, SW1A 2AA")<br/>
		latlng = scraperwiki.geo.gb_postcode_to_latlng("SW1A 2AA")<br/>
		oslatlng = scraperwiki.geo.os_easting_northing_to_latlng(528882,179839)
		</code></div>
        </div>


<hr style="margin-top:40px"/>
<div class="staff">
<h2>Deprecated functions</h2>
        <div class="section">
            <h3><span id="saving"></span>scraperwiki.datastore.save</h3>
            <p>Save your data to the ScraperWiki datastore. You can then download it, 
            or retrieve it later using the API. </p>
			    <h4>Method</h4>
			    <table class="api_detail example_table">
			    <tr><th width="30%">Method</th><th width="20%">Returned value</th><th>Description</th></tr>
				<tr><td><code>scraperwiki.datastore.save<br/>
				    &nbsp;(unique_keys, data,<br/>
				    &nbsp;[date=],<br/>
				    &nbsp;[latlng=]) </code></td>
				<td>None</td>
			    <td>
			    <p>Stores a new record in the database, or replaces an existing
                record which has the same unique keys. The data parameter is a
                dictionary containing all the attributes of your record and their
                values.
                </p>
                <dl>
                    <dt><code>unique_keys</code></dt>
                        <dd>Array. Specify the attributes in
                        your record which are together unique, e.g. <code>['dog_id']</code> or
                        <code>['cattery', 'cat_number']</code>. Any existing data with
                        the same values for those attributes as your new data
                        will be overwritten. Must contain at least one element.
                        </dd>
                    <dt><code>data</code></dt>
                        <dd>Dictionary. The data in your record. Values are converted to strings, e.g.
                        in the example given, 
                        the integer <code>9812301</code> will be stored as a string. A null value
                        (e.g. <code>None</code> in Python) is stored as an empty string.
                        For string values, pass in either a Unicode string or a byte string encoded in UTF-8.
                        As a special case, if you use a key called <code>'date'</code> or <code>'latlng'</code>,
                        then it will be treated as if it were one of the optional arguments described below.
                        </dd>
                    <dt><code>date</code> (optional)</dt>
                        <dd>Special date/time field. You can later retrieve
                        information according to this date using the <a href="{% url api:scraper_getdatabydate %}">getDataByDate</a>
                        function in the external API. You can also store dates
                        in the data field, but you should put the most important date in this field.
                        The date should be a date/time object (e.g. <code>datetime.datetime.now() - datetime.timedelta(weeks=2)</code>).
                        </dd>
                    <dt><code>latlng</code> (optional)</dt>
                        <dd>Optionally, a location. This is a pair containing
                        latitude and longitude coordinates, e.g. <code>(-2.983333, 53.4)</code>. The coordinates should
                        be in the WGS84 projection. You can later retrieve
                        information according to this location using the <a href="{% url api:scraper_getdatabylocation %}">getDataByLocation</a>.
                        Scrapers for which latitude and longitude coordinates have been added will have a map showing the points displayed
                        on the its page on the site.
                        </dd>
                </dl>
			    </td>
			    </tr>
			    </table>
				<h4>Example</h4>
				<div class="example"><code>
			    data = {}<br/>
			    data['name'] = 'Fluffles'<br/>
			    data['breed'] = 'Alsatian'<br/>
			    crufts_date = datetime.datetime(2003, 8, 4, 12, 30, 45)<br/>
			    scraperwiki.datastore.save(['name'], data, crufts_date, latlng=(-2.983333, 53.4))
				</code></div>
            </div>

        <div class="section">
	    <h2><span id="managing"></span>Managing scrapers with metadata</h2> 
            <p>
              Scrapers can store and retrieve metadata that is persisted between
			runs. This can be used internally by the scraper; to set the order in which 
			data columns are displayed; or to hide particular columns in the data table.
            </p>
			    <h4>Method</h4>
			    <table class="api_detail example_table">
			    <tr><th width="30%">Method</th><th width="20%">Returned value</th><th>Description</th></tr>
			<tr><td><code>scraperwiki.metadata.save<br/>&nbsp;(key, value)</code></td><td>String</td>
			    <td>
			 <p>Stores an item of metadata that can later be retrieved using the <code>scraperwiki.metadata.get</code> function.</p>
			    <dl>
	              <dt><code>key</code></dt>
	              <dd>
	                This is a unique identifier for the data being stored. Multiple save requests
	                with the same key will overwrite any existing value associated with the key.
	              </dd>
	              <dt><code>value</code></dt>
	              <dd>The value to be stored.</dd>
	            </dl></td></tr>
	            <tr>
				<td><code>scraperwiki.metadata.get<br/>&nbsp;(key, [default=])</code></td><td>String</td>
				 <td>
				 <p>Retrieves an item of metadata that has previously been stored using the <code>scraperwiki.metadata.save</code> function.</p>
				<dl>
	              <dt><code>key</code></dt>
	              <dd>The unique identifier that was used when storing the data.</dd>
	              <dt><code>default</code> (optional)</dt>
	              <dd>The value to be returned if no value is found to be associated with this key. Defaults to <code>None</code>.</dd>
	            </dl></td>
			    </tr>
			    </table>
				<h4>Example</h4>
				<div class="example"><code>
				latest_message = scraperwiki.metadata.get('latest_message', default='No message yet')<br/>
				latest_message = 'Scraper input'<br/>
				scraperwiki.metadata.save('latest_message',latest_message)
                </code></div>
                </div>

            <h3>Special Keys</h3>
            <p>
              You can store any information in metadata. However, special keys can be used to set
             column ordering in the data table, or hide columns altogether. These include:
            </p>
            <table class='data'>
              <tr><th>Key</th><th>Outcome</th></tr>
              <tr>
                <td>data_columns</td>
                <td>
                  Store a list of column names here to specify the order in which columns are displayed in the ScraperWiki data table.
                </td>
              </tr>
            </table>
			<h4>Example</h4>
			<div class="example"><code>
			scraperwiki.metadata.save('data_columns', ['date', 'name', 'breed', 'latlng'])
			</code></div>
        </div>
</div>

<div>
<h4>Core ScraperWiki Python functions</h4>
<h5>Scraping</h5>
<ul>
  <li><a href="#scraping">scraperwiki.scrape</a></li>
</ul>
<h5>SQL datastore</h5>
<ul>
  <li><a href="#sql">scraperwiki.sqlite.save</a></li>
  <li><a href="#sql">scraperwiki.sqlite.execute</a></li>
  <li><a href="#sql">scraperwiki.sqlite.select</a></li>
  <li><a href="#sql">scraperwiki.sqlite.commit</a></li>
  <li><a href="#sql">scraperwiki.sqlite.attach</a></li>
  <li><a href="#variables">scraperwiki.sqlite.save_var</a></li>
  <li><a href="#variables">scraperwiki.metadata.get_var</a></li>
</ul>
<h5>Geo</h5>
<ul>
  <li><a href="#geocoding">scraperwiki.geo.extract_gb_postcode</a></li>
  <li><a href="#geocoding">scraperwiki.geo.gb_postcode_to_latlng</a></li>
  <li><a href="#geocoding">scraperwiki.geo.os_easting_northing_to_latlng</a></li>
</ul>
<h5>Deprecated</h5>
<ul>
  <li><a href="#saving">scraperwiki.datastore.save</a></li>
  <li><a href="#managing">scraperwiki.metadata.save</a></li>
  <li><a href="#managing">scraperwiki.metadata.get</a></li>
</ul> 
</div>


