{% extends "frontend/base.html" %}

{% block title %}Help{% endblock %}
{% block content %}
    <div class="page_title">
        <h1>Help</h1>
        <p>
            ScraperWiki help and frequently asked questions
        </p>
    </div>
    <div class="content">
        <ul class="list_of_contents">
            <li><a href="#what">What is ScraperWiki?</a></li>
            <li><a href="#who">Who is ScraperWiki for?</a></li>
            <li><a href="#languages">What programming languages can I use to write scrapers?</a></li>
            <li><a href="#libraries">What libraries are available?</a></li>
            <li><a href="#how">How do I write a screen scraper?</a></li>
            <li><a href="#saving">What's the difference between saving and committing/publishing my scraper?</a></li>
            <li><a href="#running">How do I run my scraper?</a></li>
            <li><a href="#editing">Who can edit a scraper?</a></li>
            <li><a href="#data">How to get data out of ScraperWiki?</a></li>
            <li><a href="#errors">What happens if my scraper breaks?</a></li>
            <li><a href="#licence">Who owns the code I write on ScraperWiki?</a></li>                                        
            <li><a href="#data_ownership">Who owns the data in ScraperWiki?</a></li>                                
            <li><a href="data_types">What sort of data can/can't I scrape?</a></li>                                        
            <li><a href="#security">How secure is your system? Can I try and break it?</a></li>
            <li><a href="#contact">How do I get in touch with you?</a></li>
        </ul>

        <dl class="faq">
            <dt id="what">What is ScraperWiki?</dt>

            <dd>
                <p>ScraperWiki is a platform for writing and scheduling <a href="http://en.wikipedia.org/wiki/Data_scraping">screen scrapers</a>, and for storing the data they generate. There's lots of useful data locked away on the internet and we want to open it up!
                </p>

                <p>If you need a parallel, <a href="http://www.dracos.co.uk/play/great-ideas-generator/">and every self respecting website does</a>, then it's like GitHub, except with an execute button and a database behind it.
                </p>
            </dd>
            <dt id="who">Who is ScraperWiki for?<dt>

            <dd>
                <p>ScraperWiki is useful both for programers who want to write screen scrapers with less fuss, and for journalists, activists and the general public who want to discover and re-use interesting, useful data.
                </p>
            </dd>

            <dt id="languages">What programming languages can I use to write scrapers?</dt>

            <dd>
                <p>
                We only support Python at the moment, but will be adding more languages soon on the basis of who <a href="/contact/">shouts loudest</a>.
                </p>
            </dd>
            <dt id="libraries">What libraries are available?</dt>
            <dd>
                <ul>
                    <li><a href="http://www.python.org/doc/2.5/lib/lib.html">Standard python 2.5 libraries</a></li>
                    <li><a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>
                    <li><a href="http://wwwsearch.sourceforge.net/mechanize/">mechanize</a></li>
                    <li><a href="http://codespeak.net/lxml/">lxml</a> / <a href="http://code.google.com/p/html5lib/wiki/UserDocumentation">html5lib</a></li>
                    <li>pdftohtml</li>
                    <li><a href="http://www.imagemagick.org/script/convert.php">imagemagic convert</a></li>
                </ul>
            </dd>

            <dt id="how">How do I write a screen scraper?</dt>
            <dd>
                <p>
                    You write a scraper using our <a href="/editor/">online editor</a>. 
                </p>
                <p>
                    Use the <code>scraperwiki.scrape(url)</code> function to download a web page. Extract the data you want, and then use the <code>datastore.save(unique_keys, data, date=None, latlng=[None, None])</code> function to save your data.
                </p>
                <p>
                    <code>date</code> and <code>latlng</code> are optional indexes for date and location (these are for extracting data more efficiantly from our API).
                </p>
                <p>
                    The editor has 3 tabs: <strong>console</strong> is for printing debug output from your scraper and displaying error messages; <strong>data</strong> shows the data your scraper would save to the datastore; <strong>sources</strong> shows the URLs you are scraping.
                </p>
                <p>
                    Once you have written your scraper, click 'commit and publish' to publish your scraper and schedule it to run.
                </p>
            </dd>

            <dt id="saving">What's the difference between saving and committing/publishing my scraper?</dt>

            <dd>
                <p>Clicking the save button in the editor saves your work (by saving it to disk on our servers) without publishing it on ScraperWiki or changing what code is run each day. This means you can continue working on it later, or pair program with someone else on the same scraper.
                </p>

                <p>Committing your scraper creates a new version (using the <a href="http://mercurial.selenic.com/">Mercurial</a> source control system) and publishes it on ScraperWiki. The next time your scraper is called by the scheduler your committed code will be this code that gets run.
                </p>
            </dd>

            <dt id="running">How do I run my scraper?</dt>

            <dd>
                <p>
                    At the moment the committed version of each scraper in ScraperWiki is run once a day by our scheduler. We are adding extra controls so you can set how ofter your scraper needs to run. So if you know a web page only gets updated once a month on a tuesday, you can set it to run then.
                </p>
            </dd>
            <dt id="editing">Who can edit a scraper?</dt>

            <dd>
                <p>At the moment anyone can edit anyone else's scraper, this means other people can help extend or fix your code. We are adding email alerts so you when your scraper is edited and by who, and eventually the option to have private scrapers. If you are interested in this, please <a href="/contact/">get in touch</a>. 
                </p>
            </dd>

            <dt id="data">How to get data out of ScraperWiki?</dt>

            <dd>
                <p>The simplest way is to download a CSV file from the link on the scraper page. We are also building an API and adding RSS feeds. We'd really <a href="/contact/">like your thoughts</a> on how these should work.
                </p>
            </dd>


            <dt id="errors">What happens if my scraper breaks?</dt>

            <dd>
                <p>We are currently building the system that will alert you by email if your scrapers appear to be broken.
                </p>
            </dd>


            <dt id="licence">Who owns the code I write on ScraperWiki?</dt>

            <dd>
                <p>All scraping code hosted on ScraperWiki is licensed under the <a href="http://www.gnu.org/licenses/gpl-3.0.txt">GNU General Public License</a>. By adding your scraper to ScraperWiki you are releaseing it under the same licence. For more information please see our <a href="/terms_and_conditions/">terms and conditions</a>.
                </p>
            </dd>

            <dt id="data_ownership">Who owns the data in ScraperWiki?</dt>

            <dd>
                <p>It depends where the data originally came from and how it was derived. The source and licence of the data is declared in the details for each scraper. When creating a scraper you will be asked to enter this data.
                </p>
            </dd>

            <dt id="data_types">What sort of data can/can't I scrape?</dt>

            <dd>
                <p>The focus of ScraperWiki is opening up public data. You need to make sure that you confirm to our <a href="/terms_and_conditions/">terms and conditions</a>. In short play nice, and don't do to someone else's website what you wouldent like done to yourself.
                </p>
            </dd>

            <dt id="security">How secure is your system? Can I try and break it?</dt>

            <dd>
                <p>The code you write runs in a seperate sandboxed system with controlled resources. If you try and write malicious code (while 1=1, that kind of thing) you'll just be breaking your own scraper and annoying people, so please don't.
                </p>
            </dd>

            <dt id="contact">How do I get in touch with you?</dt>

            <dd>
                <p>You can contact us <a href="/contact/">here</a> or ask a question on our <a href="http://groups.google.com/group/scraperwiki">email list</a>.
                </p>
            </dd>

        </dl>
    </div>
{% endblock %}