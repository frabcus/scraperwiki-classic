INSTALLING WITH BUILDOUT

[[Windows-specific installation notes in double square brackets throughout]]

Requirements
============

* Working python (2.5 or greater, not python 3)
* MySQL installed with root access (on Windows, v5.1)
* Mercurial
* (optional) python's virtualenv

Installation
============

The 'root' folder from now on will refer to the root of the mercurial checkout - in other words, the folder containing buildout, web, datastore etc. [In Windows, make sure there are no spaces in the folder names.]


1) Set up Virtualenv
************************************************

a) From within the root folder, run (note the dot at the end):

> $ virtualenv --no-site-packages .

This will create a new virtualenv with all its folders alongside the scraperwiki code. If virtualenv is not installed, you can download it from http://www.python.org/download or install using macports if you are using OSX. Note: the macports version needs to be called using "> virtualenv2.x  --no-site-packages ."

b) Now activate the virtualenv:

> $ source bin/activate

[[In Windows, type: > Scripts\activate.bat  ]]

Your shell will now show the virtualenv name "> (scraperwiki)$" at the prompt. This indicates the virtualenv is 'active'.  

YOU WILL TO DO THIS EACH TIME YOU OPEN A NEW SESSION IN YOUR SHELL. See http://pypi.python.org/pypi/virtualenv for more.

c) Then, get the older version of pip, version 0.6 breaks some old code. Go to [root]\lib\site-packages and remove anything to with pip, then run 

> $ easy_install pip==0.5.1


2) Buildout
***********

To run the buildout, first bootstrap it:

> $ python bootstrap.py

Then run buildout [[except on Windows, see notes below]]:

> $ buildout 

[[ In Windows, this would be, : > "./bin/buildout.exe" - but in fact we need to skip it altogether, so just do "pip install xxx" for each 'install' command in the 'pip' section of buildout.cfg, EXCEPT python-mysql.
For python-mysql, download MySQL-python-1.2.2.win32-py2.6.exe from http://www.codegood.com/archives/4, install it on your machine, then copy all the python-mysql-related files from C:\Python26\Lib\site-packages or into the lib\site-packages directory of your virtualenv. ]]

This will download all the packages needed by scraperwiki.

If you get a weird error something like "setuptools.dist has no 'check_packages' attribute",
then run this command and then try buildout again:

> $ easy_install -U distribute

Note, sometimes this causes a "SandboxViolation" error, however it's normally 
done what it needs to do before this, so ignore the error and run buildout
again.

3) localsettings.py
*******************

Now, make a copy of the local settings file and edit it

> $ cd web
> $ cp localsettings.py-inhg  localsettings.py

Then edit localsettings.py to:

a) Add details of your local setup (database etc). Call the database 'scraperwiki'. 

b) Edit HOME_DIR to your scraperwiki home directory. [[In Windows, do use forward slashes in the directory path.]]


4) Run Django
*************

Test the install by moving in to the web directory and running 'syncdb' and 'migrate':

> $ cd web
> $ python manage.py syncdb
> $ python manage.py migrate

Now try running django:

> $ python manage.py runserver

Assuming no errors you should be able to visit http://localhost:8000/ and see the scraperwiki home page.

You should go to http://localhost:8000/admin and configure the 'sites' section.

At the very least you need to change 'example.com' to 'localhost:8000'.

Make sure you visit localhost (NOT 127.0.0.1) because otherwise you'll get
cross-site scripting errors relating to the orbited Javascript.



5) Initiate the Firebox
***********************

Screen scrapers run inside a virtual machine "firebox" using User Mode Linux (UML).

a) Install twisted and orbited on your machine. e.g. "apt-get install python-twisted", "easy_install orbited"

b) Checkout the separare UML repository. You don't want it in the scraperwiki folder, but in a parallel one.  

> $ hg clone ssh://scraperwiki@212.84.75.28/UML

c) Copy Server/scripts/runner_config.py.inhg to a version without .inhg and change the paths inside.

d) For development sites, the FireBox subsystem can be run without UML by running the command
> $ ./runlocal
It will spawn some magical things in the background. To stop them use killlocal. See UML/LOCAL for more information, including debugging. 

For live sites, you will need to read UML/HOWTO. XXX It isn't up to date. Please quiz Mike and update it if you do this

e) In web/localsettings.py set FIREBOX_PATH to the full path of the UML/Server/scripts directory, e.g. '/home/francis/devel/UML/Server/scripts'

f) In UML/Server/scripts copy SWConfig.py.in_hg to SWConfig.py and edit it. For now, set "host = None" to disable logging.
You can make a MySQL database to log into another time. XXX update instructions to explain how to do that when it is
more stable


6) Create the scrapers' Mercurial repository
********************************************

Create a new repository to store the screen scrapers in.

> $ cd scraperwiki
> $ hg init scrapers


7) Create the scrapers' datastore
*********************************

Next, in MySQL, create a database called scraperwiki_datastore:
mysql> create database scraperwiki_datastore;

There are two configuration files which need pointing to the database.

a) In web/localsettings.py, edit the DATASTORE_DATABASE_* entries. This is access for the Django web application, for example for the API to read from the datastore. A read only database user might be enough for this.

b) In ./scraperlibs/scraperwiki/datastore, copy config.cfg-inhg to config.cfg.local and edit it. This is the config used by the scrapers to write to the database. You need a user who can read/write to the database.

Then change to the datastore directory, and use mysql to import the database schema, scheme.sql:

> $ cd ./scraperlibs/scraperwiki/datastore
> $ mysql -u USERNAME -p -h localhost scraperwiki_datastore < scheme.sql

And you should be done.

